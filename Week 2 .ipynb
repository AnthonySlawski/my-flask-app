{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1db444be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, StratifiedKFold, cross_val_predict, KFold, learning_curve, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import cross_validate, KFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d923f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desktop Data:\n",
      "        Nativelang  Otherlang  Age  Clicks1  Hits1  Misses1  Score1  \\\n",
      "Gender                                                                \n",
      "Male             0          1    7       10     10        0      10   \n",
      "Female           1          1   13       12     12        0      12   \n",
      "Female           0          1    7        6      6        0       6   \n",
      "Female           0          1    7        0      0        0       0   \n",
      "Female           0          1    8        4      4        0       4   \n",
      "\n",
      "        Accuracy1  Missrate1  Clicks2  ...  Score31  Accuracy31  Missrate31  \\\n",
      "Gender                                 ...                                    \n",
      "Male          1.0        0.0        5  ...        0    0.000000        0.00   \n",
      "Female        1.0        0.0       11  ...        4    0.114286        0.00   \n",
      "Female        1.0        0.0        6  ...        4    0.114286        0.00   \n",
      "Female        0.0        0.0        0  ...        0    0.000000        0.00   \n",
      "Female        1.0        0.0        8  ...        1   25.000000        0.05   \n",
      "\n",
      "        Clicks32  Hits32  Misses32  Score32  Accuracy32  Missrate32  Dyslexia  \n",
      "Gender                                                                         \n",
      "Male          17       2         0        2    0.117647    0.000000         0  \n",
      "Female        26       2         2        2    0.076923    0.076923         1  \n",
      "Female        26       1         3        1    0.038462    0.115385         0  \n",
      "Female         1       0         0        0    0.000000    0.000000         0  \n",
      "Female        26       2         2        2    0.076923    0.076923         0  \n",
      "\n",
      "[5 rows x 196 columns]\n",
      "\n",
      "Tablet Data:\n",
      "        Nativelang  Otherlang  Age  Clicks1  Hits1  Misses1  Score1  \\\n",
      "Gender                                                                \n",
      "Male             1          0    7        6      6        0       6   \n",
      "Female           1          0    7        7      7        0       7   \n",
      "Female           1          0    7        6      6        0       6   \n",
      "Male             1          0    7        5      5        0       5   \n",
      "Male             1          0    7        8      6        2       8   \n",
      "\n",
      "        Accuracy1  Missrate1  Clicks2  ...  Score31  Accuracy31  Missrate31  \\\n",
      "Gender                                 ...                                    \n",
      "Male         1.00       0.00        5  ...      nan         nan         nan   \n",
      "Female       1.00       0.00        7  ...      nan         nan         nan   \n",
      "Female       1.00       0.00        7  ...      nan         nan         nan   \n",
      "Male         1.00       0.00        5  ...      nan         nan         nan   \n",
      "Male         0.75       0.25        4  ...      nan         nan         nan   \n",
      "\n",
      "        Clicks32  Hits32  Misses32  Score32  Accuracy32  Missrate32  Dyslexia  \n",
      "Gender                                                                         \n",
      "Male         nan     nan       nan      nan         nan         nan         0  \n",
      "Female       nan     nan       nan      nan         nan         nan         0  \n",
      "Female       nan     nan       nan      nan         nan         nan         0  \n",
      "Male         nan     nan       nan      nan         nan         nan         0  \n",
      "Male         nan     nan       nan      nan         nan         nan         0  \n",
      "\n",
      "[5 rows x 196 columns]\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "dfile_path = r\"C:\\Users\\antho\\OneDrive - University College Dublin\\ACM20030 1\\ALPACA\\Dyt-desktop.csv\"\n",
    "tfile_path = r\"C:\\Users\\antho\\OneDrive - University College Dublin\\ACM20030 1\\ALPACA\\Dyt-tablet.csv\"\n",
    "\n",
    "# Read and clean CSV data\n",
    "def clean_csv(file_path, delimiter=';', na_values=['(NA)']):\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(file_path, delimiter=delimiter, na_values=na_values, index_col=0)\n",
    "    \n",
    "    # Clean the data, convert applicable data to numerical\n",
    "    data = data.applymap(str).apply(pd.to_numeric, errors='ignore')\n",
    "    \n",
    "    # Map categorical data to numeric values\n",
    "    mappings = {\n",
    "        'Gender': {'Male': 1, 'Female': 2},\n",
    "        'Dyslexia': {'No': 0, 'Yes': 1},\n",
    "        'Nativelang': {'No': 0, 'Yes': 1},\n",
    "        'Otherlang': {'No': 0, 'Yes': 1}\n",
    "    }\n",
    "\n",
    "    for col, mapping in mappings.items():\n",
    "        if col in data.columns:\n",
    "            data[col] = data[col].map(mapping)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Display data\n",
    "dData = clean_csv(dfile_path)\n",
    "tData = clean_csv(tfile_path)\n",
    "\n",
    "print('Desktop Data:')\n",
    "print(dData.head())\n",
    "\n",
    "print('\\nTablet Data:')\n",
    "print(tData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a388328",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dData['Dyslexia']\n",
    "X = dData.drop(columns=['Dyslexia'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a2d13d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9026063100137174\n"
     ]
    }
   ],
   "source": [
    "#----RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train , y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0930d3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8998628257887518\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "model = neighbors.KNeighborsClassifier()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a74aeea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8902606310013718\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model=svm.SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a73ef5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8902606310013718\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "def euclidean(point, dataset):\n",
    "    squared_diff = np.square(dataset - point)\n",
    "    sum_squared_diff = np.sum(squared_diff, axis=1)\n",
    "    return np.sqrt(sum_squared_diff)\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, n_clusters=8, max_iter=300, random_state=0):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X_train):\n",
    "        X_train = np.array(X_train)\n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        # Pick a random point from train data for first centroid\n",
    "        self.centroids = [X_train[random.choice(range(X_train.shape[0]))]]\n",
    "        \n",
    "        # Set the remaining initial guesses using the k-means++ method\n",
    "        for _ in range(self.n_clusters - 1):\n",
    "            dists = np.min([euclidean(centroid, X_train) for centroid in self.centroids], axis=0)\n",
    "            dists /= np.sum(dists)\n",
    "            new_centroid_idx = np.random.choice(range(len(X_train)), size=1, p=dists)[0]\n",
    "            self.centroids.append(X_train[new_centroid_idx])\n",
    "        \n",
    "        self.centroids = np.array(self.centroids)\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            sorted_points = [[] for _ in range(self.n_clusters)]\n",
    "            \n",
    "            for x in X_train:\n",
    "                dists = euclidean(x, self.centroids)\n",
    "                centroid_idx = np.argmin(dists)\n",
    "                sorted_points[centroid_idx].append(x)\n",
    "                \n",
    "            prev_centroids = self.centroids.copy()\n",
    "            self.centroids = [np.mean(cluster, axis=0) if len(cluster) > 0 else prev_centroids[i]\n",
    "                              for i, cluster in enumerate(sorted_points)]\n",
    "            \n",
    "            if np.array_equal(prev_centroids, self.centroids):\n",
    "                break\n",
    "\n",
    "    def evaluate(self, X):\n",
    "        X = np.array(X)\n",
    "        centroid_idxs = []\n",
    "        for x in X:\n",
    "            dists_cent = euclidean(x, self.centroids)\n",
    "            closest_centroid_idx = np.argmin(dists_cent)\n",
    "            centroid_idxs.append(closest_centroid_idx)\n",
    "        return centroid_idxs\n",
    "\n",
    "model = KMeans(n_clusters=1)\n",
    "model.fit(X_train)\n",
    "y_pred = model.evaluate(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7371b611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "model = DBSCAN(eps=0.5)\n",
    "y_train_pred = model.fit_predict(X_train)\n",
    "y_test_pred = model.fit_predict(X_test)\n",
    "\n",
    "print(\"Adjusted Rand Index:\", metrics.adjusted_rand_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "361a7806",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scaler\u001b[38;5;241m=\u001b[39m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241m.\u001b[39mStandardScaler()\n\u001b[0;32m      2\u001b[0m Xn\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "scaler=preprocessing.StandardScaler()\n",
    "Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b6ed8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f36c101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)), \n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa6c2060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9130 - loss: 0.2932 - val_accuracy: 0.8937 - val_loss: 0.4030\n",
      "Epoch 2/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.2769 - val_accuracy: 0.8576 - val_loss: 0.5121\n",
      "Epoch 3/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.3288 - val_accuracy: 0.8885 - val_loss: 0.5134\n",
      "Epoch 4/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2563 - val_accuracy: 0.8868 - val_loss: 0.4046\n",
      "Epoch 5/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2099 - val_accuracy: 0.8799 - val_loss: 0.4107\n",
      "Epoch 6/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.2364 - val_accuracy: 0.8851 - val_loss: 0.4085\n",
      "Epoch 7/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2087 - val_accuracy: 0.8919 - val_loss: 0.4359\n",
      "Epoch 8/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9358 - loss: 0.1812 - val_accuracy: 0.8799 - val_loss: 0.3850\n",
      "Epoch 9/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.1871 - val_accuracy: 0.8885 - val_loss: 0.4134\n",
      "Epoch 10/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.2150 - val_accuracy: 0.8662 - val_loss: 0.4267\n",
      "Epoch 11/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.1534 - val_accuracy: 0.8731 - val_loss: 0.4038\n",
      "Epoch 12/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9342 - loss: 0.1725 - val_accuracy: 0.8885 - val_loss: 0.3984\n",
      "Epoch 13/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2025 - val_accuracy: 0.8799 - val_loss: 0.3695\n",
      "Epoch 14/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.1748 - val_accuracy: 0.8799 - val_loss: 0.3963\n",
      "Epoch 15/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.1672 - val_accuracy: 0.8902 - val_loss: 0.3692\n",
      "Epoch 16/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.1460 - val_accuracy: 0.8868 - val_loss: 0.3864\n",
      "Epoch 17/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.1592 - val_accuracy: 0.8954 - val_loss: 0.4002\n",
      "Epoch 18/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1357 - val_accuracy: 0.8937 - val_loss: 0.3967\n",
      "Epoch 19/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1322 - val_accuracy: 0.8937 - val_loss: 0.4129\n",
      "Epoch 20/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9390 - loss: 0.1580 - val_accuracy: 0.8868 - val_loss: 0.4228\n",
      "Epoch 21/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1275 - val_accuracy: 0.8868 - val_loss: 0.4227\n",
      "Epoch 22/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1343 - val_accuracy: 0.8885 - val_loss: 0.4321\n",
      "Epoch 23/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1249 - val_accuracy: 0.8834 - val_loss: 0.4444\n",
      "Epoch 24/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.1191 - val_accuracy: 0.8816 - val_loss: 0.4106\n",
      "Epoch 25/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1165 - val_accuracy: 0.8834 - val_loss: 0.4529\n",
      "Epoch 26/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9516 - loss: 0.1304 - val_accuracy: 0.8919 - val_loss: 0.4609\n",
      "Epoch 27/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1199 - val_accuracy: 0.8937 - val_loss: 0.4547\n",
      "Epoch 28/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1119 - val_accuracy: 0.8816 - val_loss: 0.4638\n",
      "Epoch 29/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9496 - loss: 0.1230 - val_accuracy: 0.8782 - val_loss: 0.4618\n",
      "Epoch 30/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9681 - loss: 0.1043 - val_accuracy: 0.8885 - val_loss: 0.4474\n",
      "Epoch 31/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.0919 - val_accuracy: 0.8714 - val_loss: 0.5064\n",
      "Epoch 32/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9597 - loss: 0.1023 - val_accuracy: 0.8919 - val_loss: 0.4886\n",
      "Epoch 33/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9678 - loss: 0.0901 - val_accuracy: 0.8834 - val_loss: 0.5005\n",
      "Epoch 34/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.0957 - val_accuracy: 0.8799 - val_loss: 0.5759\n",
      "Epoch 35/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.1771 - val_accuracy: 0.8799 - val_loss: 0.5305\n",
      "Epoch 36/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.0878 - val_accuracy: 0.8765 - val_loss: 0.5746\n",
      "Epoch 37/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9733 - loss: 0.0820 - val_accuracy: 0.8816 - val_loss: 0.5449\n",
      "Epoch 38/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9690 - loss: 0.0819 - val_accuracy: 0.8731 - val_loss: 0.5718\n",
      "Epoch 39/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1041 - val_accuracy: 0.8971 - val_loss: 0.5532\n",
      "Epoch 40/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.0849 - val_accuracy: 0.8937 - val_loss: 0.5890\n",
      "Epoch 41/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0671 - val_accuracy: 0.8834 - val_loss: 0.6032\n",
      "Epoch 42/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.0774 - val_accuracy: 0.8782 - val_loss: 0.6313\n",
      "Epoch 43/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.0772 - val_accuracy: 0.8885 - val_loss: 0.6759\n",
      "Epoch 44/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0649 - val_accuracy: 0.8799 - val_loss: 0.6628\n",
      "Epoch 45/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0575 - val_accuracy: 0.9022 - val_loss: 0.7111\n",
      "Epoch 46/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.0627 - val_accuracy: 0.9022 - val_loss: 0.7520\n",
      "Epoch 47/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.0595 - val_accuracy: 0.8851 - val_loss: 0.7280\n",
      "Epoch 48/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0583 - val_accuracy: 0.8971 - val_loss: 0.7572\n",
      "Epoch 49/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0471 - val_accuracy: 0.8645 - val_loss: 0.7851\n",
      "Epoch 50/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.0638 - val_accuracy: 0.8868 - val_loss: 0.7811\n",
      "Epoch 51/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.0694 - val_accuracy: 0.9005 - val_loss: 0.8565\n",
      "Epoch 52/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.1030 - val_accuracy: 0.8765 - val_loss: 0.7545\n",
      "Epoch 53/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9790 - loss: 0.0832 - val_accuracy: 0.8714 - val_loss: 0.6585\n",
      "Epoch 54/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0478 - val_accuracy: 0.8868 - val_loss: 0.6606\n",
      "Epoch 55/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0372 - val_accuracy: 0.8885 - val_loss: 0.7358\n",
      "Epoch 56/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0417 - val_accuracy: 0.8851 - val_loss: 0.7303\n",
      "Epoch 57/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0366 - val_accuracy: 0.8834 - val_loss: 0.7542\n",
      "Epoch 58/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0539 - val_accuracy: 0.8885 - val_loss: 0.7721\n",
      "Epoch 59/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0398 - val_accuracy: 0.8937 - val_loss: 0.7902\n",
      "Epoch 60/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0526 - val_accuracy: 0.8782 - val_loss: 0.7834\n",
      "Epoch 61/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0431 - val_accuracy: 0.8937 - val_loss: 0.7598\n",
      "Epoch 62/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0446 - val_accuracy: 0.8885 - val_loss: 0.7983\n",
      "Epoch 63/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0298 - val_accuracy: 0.8868 - val_loss: 0.8322\n",
      "Epoch 64/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0353 - val_accuracy: 0.8954 - val_loss: 0.9281\n",
      "Epoch 65/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0431 - val_accuracy: 0.8765 - val_loss: 0.9456\n",
      "Epoch 66/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.0895 - val_accuracy: 0.8834 - val_loss: 0.9767\n",
      "Epoch 67/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0425 - val_accuracy: 0.8971 - val_loss: 1.0593\n",
      "Epoch 68/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0450 - val_accuracy: 0.8868 - val_loss: 0.8736\n",
      "Epoch 69/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0355 - val_accuracy: 0.8868 - val_loss: 0.9304\n",
      "Epoch 70/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0316 - val_accuracy: 0.8885 - val_loss: 0.9791\n",
      "Epoch 71/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0193 - val_accuracy: 0.8971 - val_loss: 0.9974\n",
      "Epoch 72/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.0221 - val_accuracy: 0.8919 - val_loss: 1.0440\n",
      "Epoch 73/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0167 - val_accuracy: 0.9005 - val_loss: 1.0648\n",
      "Epoch 74/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0212 - val_accuracy: 0.8954 - val_loss: 1.0443\n",
      "Epoch 75/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0163 - val_accuracy: 0.8954 - val_loss: 1.0715\n",
      "Epoch 76/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0180 - val_accuracy: 0.8988 - val_loss: 1.1432\n",
      "Epoch 77/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0194 - val_accuracy: 0.9005 - val_loss: 1.1783\n",
      "Epoch 78/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0173 - val_accuracy: 0.8937 - val_loss: 1.1996\n",
      "Epoch 79/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0211 - val_accuracy: 0.8919 - val_loss: 1.1846\n",
      "Epoch 80/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0150 - val_accuracy: 0.8885 - val_loss: 1.1817\n",
      "Epoch 81/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0214 - val_accuracy: 0.8937 - val_loss: 1.2220\n",
      "Epoch 82/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0187 - val_accuracy: 0.8971 - val_loss: 1.2315\n",
      "Epoch 83/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0184 - val_accuracy: 0.9057 - val_loss: 1.2600\n",
      "Epoch 84/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0362 - val_accuracy: 0.8954 - val_loss: 1.2386\n",
      "Epoch 85/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0405 - val_accuracy: 0.8919 - val_loss: 1.2298\n",
      "Epoch 86/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0253 - val_accuracy: 0.8902 - val_loss: 1.2104\n",
      "Epoch 87/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0201 - val_accuracy: 0.8937 - val_loss: 1.2291\n",
      "Epoch 88/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0223 - val_accuracy: 0.8799 - val_loss: 1.2713\n",
      "Epoch 89/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0103 - val_accuracy: 0.8851 - val_loss: 1.3196\n",
      "Epoch 90/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9892 - loss: 0.0305 - val_accuracy: 0.8799 - val_loss: 1.2878\n",
      "Epoch 91/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0163 - val_accuracy: 0.8937 - val_loss: 1.3220\n",
      "Epoch 92/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0486 - val_accuracy: 0.8902 - val_loss: 1.2974\n",
      "Epoch 93/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1328 - val_accuracy: 0.9039 - val_loss: 1.0523\n",
      "Epoch 94/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9620 - loss: 0.0989 - val_accuracy: 0.8834 - val_loss: 0.9391\n",
      "Epoch 95/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0665 - val_accuracy: 0.8388 - val_loss: 1.0908\n",
      "Epoch 96/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9711 - loss: 0.0931 - val_accuracy: 0.8696 - val_loss: 1.0082\n",
      "Epoch 97/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0273 - val_accuracy: 0.8731 - val_loss: 1.0924\n",
      "Epoch 98/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0243 - val_accuracy: 0.8628 - val_loss: 1.0423\n",
      "Epoch 99/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0167 - val_accuracy: 0.8954 - val_loss: 0.9951\n",
      "Epoch 100/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0272 - val_accuracy: 0.8851 - val_loss: 0.9886\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Accuracy: 0.8820301783264746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  \n",
    "# Print accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90979761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7250 - loss: 0.5396 - val_accuracy: 0.8662 - val_loss: 0.3015\n",
      "Epoch 2/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8942 - loss: 0.2480 - val_accuracy: 0.8748 - val_loss: 0.2975\n",
      "Epoch 3/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.2271 - val_accuracy: 0.8851 - val_loss: 0.2937\n",
      "Epoch 4/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.1686 - val_accuracy: 0.8834 - val_loss: 0.2925\n",
      "Epoch 5/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.1667 - val_accuracy: 0.8834 - val_loss: 0.2974\n",
      "Epoch 6/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9361 - loss: 0.1470 - val_accuracy: 0.8937 - val_loss: 0.2887\n",
      "Epoch 7/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1253 - val_accuracy: 0.8885 - val_loss: 0.2864\n",
      "Epoch 8/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9494 - loss: 0.1199 - val_accuracy: 0.9057 - val_loss: 0.2998\n",
      "Epoch 9/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.0965 - val_accuracy: 0.8971 - val_loss: 0.2962\n",
      "Epoch 10/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0915 - val_accuracy: 0.8971 - val_loss: 0.3055\n",
      "Epoch 11/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9679 - loss: 0.0822 - val_accuracy: 0.8988 - val_loss: 0.3175\n",
      "Epoch 12/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0764 - val_accuracy: 0.8954 - val_loss: 0.3224\n",
      "Epoch 13/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0591 - val_accuracy: 0.8851 - val_loss: 0.3307\n",
      "Epoch 14/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0520 - val_accuracy: 0.8851 - val_loss: 0.3525\n",
      "Epoch 15/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0542 - val_accuracy: 0.8971 - val_loss: 0.3365\n",
      "Epoch 16/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0425 - val_accuracy: 0.8885 - val_loss: 0.3647\n",
      "Epoch 17/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0392 - val_accuracy: 0.8954 - val_loss: 0.3674\n",
      "Epoch 18/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0311 - val_accuracy: 0.8902 - val_loss: 0.3813\n",
      "Epoch 19/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0286 - val_accuracy: 0.8937 - val_loss: 0.3761\n",
      "Epoch 20/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0273 - val_accuracy: 0.8937 - val_loss: 0.3926\n",
      "Epoch 21/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0245 - val_accuracy: 0.8885 - val_loss: 0.4063\n",
      "Epoch 22/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0199 - val_accuracy: 0.8988 - val_loss: 0.4144\n",
      "Epoch 23/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0138 - val_accuracy: 0.8971 - val_loss: 0.4298\n",
      "Epoch 24/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0135 - val_accuracy: 0.9005 - val_loss: 0.4382\n",
      "Epoch 25/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0109 - val_accuracy: 0.8919 - val_loss: 0.4490\n",
      "Epoch 26/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0093 - val_accuracy: 0.9005 - val_loss: 0.4622\n",
      "Epoch 27/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0080 - val_accuracy: 0.9022 - val_loss: 0.4688\n",
      "Epoch 28/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.9022 - val_loss: 0.4845\n",
      "Epoch 29/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9022 - val_loss: 0.4969\n",
      "Epoch 30/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.8988 - val_loss: 0.5018\n",
      "Epoch 31/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9005 - val_loss: 0.5017\n",
      "Epoch 32/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9022 - val_loss: 0.5205\n",
      "Epoch 33/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9022 - val_loss: 0.5274\n",
      "Epoch 34/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9039 - val_loss: 0.5420\n",
      "Epoch 35/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8971 - val_loss: 0.5416\n",
      "Epoch 36/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9022 - val_loss: 0.5513\n",
      "Epoch 37/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8937 - val_loss: 0.5622\n",
      "Epoch 38/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9039 - val_loss: 0.5701\n",
      "Epoch 39/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8988 - val_loss: 0.5755\n",
      "Epoch 40/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9022 - val_loss: 0.5803\n",
      "Epoch 41/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8988 - val_loss: 0.5916\n",
      "Epoch 42/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8988 - val_loss: 0.5928\n",
      "Epoch 43/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9039 - val_loss: 0.6061\n",
      "Epoch 44/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9005 - val_loss: 0.6120\n",
      "Epoch 45/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9005 - val_loss: 0.6179\n",
      "Epoch 46/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.4520e-04 - val_accuracy: 0.9005 - val_loss: 0.6223\n",
      "Epoch 47/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.8575e-04 - val_accuracy: 0.9022 - val_loss: 0.6286\n",
      "Epoch 48/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5873e-04 - val_accuracy: 0.9005 - val_loss: 0.6355\n",
      "Epoch 49/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.0934e-04 - val_accuracy: 0.9022 - val_loss: 0.6401\n",
      "Epoch 50/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.8215e-04 - val_accuracy: 0.9022 - val_loss: 0.6458\n",
      "Epoch 51/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.1342e-04 - val_accuracy: 0.9022 - val_loss: 0.6504\n",
      "Epoch 52/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.5792e-04 - val_accuracy: 0.9005 - val_loss: 0.6522\n",
      "Epoch 53/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6475e-04 - val_accuracy: 0.8988 - val_loss: 0.6583\n",
      "Epoch 54/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1632e-04 - val_accuracy: 0.9022 - val_loss: 0.6700\n",
      "Epoch 55/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3491e-04 - val_accuracy: 0.8988 - val_loss: 0.6676\n",
      "Epoch 56/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9486e-04 - val_accuracy: 0.9022 - val_loss: 0.6809\n",
      "Epoch 57/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2658e-04 - val_accuracy: 0.9005 - val_loss: 0.6838\n",
      "Epoch 58/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7191e-04 - val_accuracy: 0.8988 - val_loss: 0.6816\n",
      "Epoch 59/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6621e-04 - val_accuracy: 0.9005 - val_loss: 0.6942\n",
      "Epoch 60/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5232e-04 - val_accuracy: 0.8988 - val_loss: 0.6928\n",
      "Epoch 61/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8027e-04 - val_accuracy: 0.9005 - val_loss: 0.7006\n",
      "Epoch 62/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2378e-04 - val_accuracy: 0.9022 - val_loss: 0.7107\n",
      "Epoch 63/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8925e-04 - val_accuracy: 0.9005 - val_loss: 0.7102\n",
      "Epoch 64/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7011e-04 - val_accuracy: 0.8988 - val_loss: 0.7127\n",
      "Epoch 65/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6850e-04 - val_accuracy: 0.9022 - val_loss: 0.7231\n",
      "Epoch 66/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8626e-04 - val_accuracy: 0.9005 - val_loss: 0.7218\n",
      "Epoch 67/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2435e-04 - val_accuracy: 0.9005 - val_loss: 0.7295\n",
      "Epoch 68/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2742e-04 - val_accuracy: 0.8988 - val_loss: 0.7305\n",
      "Epoch 69/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8447e-04 - val_accuracy: 0.9005 - val_loss: 0.7346\n",
      "Epoch 70/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8124e-04 - val_accuracy: 0.9005 - val_loss: 0.7434\n",
      "Epoch 71/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6523e-04 - val_accuracy: 0.9005 - val_loss: 0.7450\n",
      "Epoch 72/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8494e-04 - val_accuracy: 0.9005 - val_loss: 0.7497\n",
      "Epoch 73/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6744e-04 - val_accuracy: 0.8971 - val_loss: 0.7496\n",
      "Epoch 74/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6450e-04 - val_accuracy: 0.9005 - val_loss: 0.7566\n",
      "Epoch 75/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4316e-04 - val_accuracy: 0.8988 - val_loss: 0.7602\n",
      "Epoch 76/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2770e-04 - val_accuracy: 0.8971 - val_loss: 0.7643\n",
      "Epoch 77/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3607e-04 - val_accuracy: 0.9022 - val_loss: 0.7691\n",
      "Epoch 78/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1117e-04 - val_accuracy: 0.8971 - val_loss: 0.7698\n",
      "Epoch 79/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1087e-04 - val_accuracy: 0.8971 - val_loss: 0.7735\n",
      "Epoch 80/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0344e-04 - val_accuracy: 0.9005 - val_loss: 0.7837\n",
      "Epoch 81/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1268e-04 - val_accuracy: 0.8971 - val_loss: 0.7823\n",
      "Epoch 82/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.6540e-05 - val_accuracy: 0.8971 - val_loss: 0.7865\n",
      "Epoch 83/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.6918e-05 - val_accuracy: 0.8988 - val_loss: 0.7936\n",
      "Epoch 84/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.2738e-05 - val_accuracy: 0.9005 - val_loss: 0.7990\n",
      "Epoch 85/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.7195e-05 - val_accuracy: 0.8971 - val_loss: 0.7975\n",
      "Epoch 86/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.9987e-05 - val_accuracy: 0.8971 - val_loss: 0.7992\n",
      "Epoch 87/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6335e-05 - val_accuracy: 0.8971 - val_loss: 0.8006\n",
      "Epoch 88/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.2501e-05 - val_accuracy: 0.8971 - val_loss: 0.8014\n",
      "Epoch 89/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.8446e-05 - val_accuracy: 0.9005 - val_loss: 0.8175\n",
      "Epoch 90/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.6165e-05 - val_accuracy: 0.8988 - val_loss: 0.8171\n",
      "Epoch 91/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.7546e-05 - val_accuracy: 0.8971 - val_loss: 0.8133\n",
      "Epoch 92/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.0436e-05 - val_accuracy: 0.9005 - val_loss: 0.8239\n",
      "Epoch 93/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.6072e-05 - val_accuracy: 0.8988 - val_loss: 0.8269\n",
      "Epoch 94/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.1233e-05 - val_accuracy: 0.8971 - val_loss: 0.8263\n",
      "Epoch 95/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.1599e-05 - val_accuracy: 0.8988 - val_loss: 0.8332\n",
      "Epoch 96/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.6447e-05 - val_accuracy: 0.8988 - val_loss: 0.8381\n",
      "Epoch 97/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.5642e-05 - val_accuracy: 0.8988 - val_loss: 0.8358\n",
      "Epoch 98/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.3333e-05 - val_accuracy: 0.9005 - val_loss: 0.8431\n",
      "Epoch 99/100\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.0903e-05 - val_accuracy: 0.8971 - val_loss: 0.8457\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.5652e-05 - val_accuracy: 0.8988 - val_loss: 0.8482\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Accuracy: 0.8902606310013718\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  \n",
    "# Print accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "scaler = StandardScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b8a73ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m100,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,250</span> (915.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m234,250\u001b[0m (915.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,250</span> (915.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m234,250\u001b[0m (915.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7621 - loss: 0.8785 - val_accuracy: 0.9005 - val_loss: 0.2694\n",
      "Epoch 2/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9036 - loss: 0.2530 - val_accuracy: 0.8954 - val_loss: 0.2680\n",
      "Epoch 3/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.2137 - val_accuracy: 0.9074 - val_loss: 0.2618\n",
      "Epoch 4/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9106 - loss: 0.2138 - val_accuracy: 0.8937 - val_loss: 0.2771\n",
      "Epoch 5/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9298 - loss: 0.1683 - val_accuracy: 0.8937 - val_loss: 0.2816\n",
      "Epoch 6/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9472 - loss: 0.1450 - val_accuracy: 0.8937 - val_loss: 0.3136\n",
      "Epoch 7/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9441 - loss: 0.1318 - val_accuracy: 0.8971 - val_loss: 0.3167\n",
      "Epoch 8/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9508 - loss: 0.1193 - val_accuracy: 0.8919 - val_loss: 0.3348\n",
      "Epoch 9/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9571 - loss: 0.0906 - val_accuracy: 0.8988 - val_loss: 0.3533\n",
      "Epoch 10/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9719 - loss: 0.0826 - val_accuracy: 0.8834 - val_loss: 0.3942\n",
      "Epoch 11/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9746 - loss: 0.0732 - val_accuracy: 0.9005 - val_loss: 0.4115\n",
      "Epoch 12/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9721 - loss: 0.0726 - val_accuracy: 0.8937 - val_loss: 0.4259\n",
      "Epoch 13/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0488 - val_accuracy: 0.8937 - val_loss: 0.4283\n",
      "Epoch 14/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9766 - loss: 0.0613 - val_accuracy: 0.8834 - val_loss: 0.4528\n",
      "Epoch 15/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9833 - loss: 0.0535 - val_accuracy: 0.8799 - val_loss: 0.4423\n",
      "Epoch 16/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9756 - loss: 0.0618 - val_accuracy: 0.8885 - val_loss: 0.4953\n",
      "Epoch 17/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9832 - loss: 0.0435 - val_accuracy: 0.9005 - val_loss: 0.5387\n",
      "Epoch 18/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9756 - loss: 0.0604 - val_accuracy: 0.8988 - val_loss: 0.4847\n",
      "Epoch 19/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9883 - loss: 0.0353 - val_accuracy: 0.9039 - val_loss: 0.4942\n",
      "Epoch 20/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9906 - loss: 0.0293 - val_accuracy: 0.9057 - val_loss: 0.5795\n",
      "Epoch 21/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0521 - val_accuracy: 0.9022 - val_loss: 0.5113\n",
      "Epoch 22/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9926 - loss: 0.0247 - val_accuracy: 0.8954 - val_loss: 0.5450\n",
      "Epoch 23/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9958 - loss: 0.0161 - val_accuracy: 0.8937 - val_loss: 0.5698\n",
      "Epoch 24/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0168 - val_accuracy: 0.8971 - val_loss: 0.6218\n",
      "Epoch 25/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0092 - val_accuracy: 0.8885 - val_loss: 0.6759\n",
      "Epoch 26/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0214 - val_accuracy: 0.8971 - val_loss: 0.6689\n",
      "Epoch 27/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0227 - val_accuracy: 0.8988 - val_loss: 0.6710\n",
      "Epoch 28/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9863 - loss: 0.0322 - val_accuracy: 0.9108 - val_loss: 0.6683\n",
      "Epoch 29/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0212 - val_accuracy: 0.8919 - val_loss: 0.7144\n",
      "Epoch 30/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0173 - val_accuracy: 0.9022 - val_loss: 0.7644\n",
      "Epoch 31/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0123 - val_accuracy: 0.9005 - val_loss: 0.7743\n",
      "Epoch 32/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0076 - val_accuracy: 0.9091 - val_loss: 0.7886\n",
      "Epoch 33/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0060 - val_accuracy: 0.8868 - val_loss: 1.1069\n",
      "Epoch 34/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0087 - val_accuracy: 0.8902 - val_loss: 0.9672\n",
      "Epoch 35/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0124 - val_accuracy: 0.8851 - val_loss: 0.9330\n",
      "Epoch 36/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0166 - val_accuracy: 0.9005 - val_loss: 0.8897\n",
      "Epoch 37/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0102 - val_accuracy: 0.8954 - val_loss: 1.0168\n",
      "Epoch 38/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0078 - val_accuracy: 0.8919 - val_loss: 0.9780\n",
      "Epoch 39/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.8988 - val_loss: 0.9600\n",
      "Epoch 40/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0169 - val_accuracy: 0.8611 - val_loss: 0.9816\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Dense Model Accuracy: 0.8573388203017832\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example data preprocessing for tabular data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the dense model for tabular data\n",
    "def make_dense_model():\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Adjust input shape\n",
    "        Dropout(0.2),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(10, activation='softmax')  # 10 classes\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the model\n",
    "dense_model = make_dense_model()\n",
    "dense_model.summary()\n",
    "\n",
    "# Training the Dense model for tabular data\n",
    "dense_history = dense_model.fit(X_train_scaled, y_train, batch_size=86, epochs=40, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Make predictions with the Dense model\n",
    "y_pred_probs_dense = dense_model.predict(X_test_scaled)\n",
    "y_pred_dense = np.argmax(y_pred_probs_dense, axis=1)\n",
    "print(\"Dense Model Accuracy:\", accuracy_score(y_test, y_pred_dense))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
